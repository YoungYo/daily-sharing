---
description: sort 命令及 uniq 命令的一个使用场景
---

# 29th

假设这样一个场景，有一天，我们的服务器遭到了黑客攻击，导致服务瘫痪，不过幸好系统记录了攻击方每一次请求的 IP，存到了日志文件 source_ip.log 中，这个文件的每一行是一个 IP 地址，格式如下：

```
139.58.xxx.xxx 
139.58.xxx.xxx 
159.195.xxx.xxx 
159.195.xxx.xxx 
198.207.xxx.xxx
……
```

这里面有大量重复的 IP，如果我想从中得到所有去重后的 IP，应该怎么做？很简单，用下面这个命令就可以搞定了：

`sort source_ip.log | uniq`

PS：为什么要先排序再去重？是因为我有强迫症吗？不是，而是 uniq 只能对有序的文本做去重。

如果我想统计每个 IP 各请求了多少次呢？也很简单，加个 -c 选项就可以，即 `sort source_ip.log | uniq -c`

再按照请求次数从多到少对 IP 进行排序？ `sort source_ip.log | uniq -c | sort -nr`

![](https://tva1.sinaimg.cn/large/008eGmZEly1gnbbgp5s0yj30sq0ekab3.jpg)
